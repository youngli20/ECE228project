{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulationClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        super(ModulationClassifier, self).__init__()\n",
    "        \n",
    "        # Treating input as 2x128 image with 1 channel (depth 1)\n",
    "        self.conv1 = torch.nn.Sequential(torch.nn.Conv2d(in_channels=1, out_channels=256, kernel_size=(1,3), padding=(0,2)), torch.nn.BatchNorm2d(256))\n",
    "        self.conv2 = torch.nn.Sequential(torch.nn.Conv2d(in_channels=256, out_channels=80, kernel_size=(2,3), padding=(0,2)), torch.nn.BatchNorm2d(80))\n",
    "        #self.fc1   = torch.nn.Linear(in_features=10560, out_features=256)\n",
    "        #self.fc2   = torch.nn.Linear(in_features=256, out_features=num_classes)\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Linear(in_features=10560, out_features=256),\n",
    "                                              torch.nn.ReLU(True),\n",
    "                                             torch.nn.Linear(in_features=256, out_features=11))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = F.relu(self.conv1(x))\n",
    "        y2 = F.relu(self.conv2(y1))\n",
    "        y3 = torch.flatten(y2, 1)\n",
    "        y4 = self.classifier(y3)\n",
    "        return y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n",
      "[-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "(0,) (0,) (0,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimage = np.zeros((220000,2,128), dtype='float32')\\nmodulation = np.zeros((220000), dtype='int32')\\nsnr = np.zeros((220000), dtype='int32')\\ncnt = 0\\n\\nfor m_cnt,m in enumerate(modulation_types,0):\\n    for s in snr_types:\\n        print(cnt, m_cnt,s)\\n        #print(input_data_dict[(m,s)].shape)\\n        image[cnt:cnt+1000,:,:] = np.array(input_data_dict[(m,s)])\\n        modulation[cnt:cnt+1000] = np.array([m_cnt for _ in range(0,1000)])\\n        snr[cnt:cnt+1000] = np.array([s for _ in range(0,1000)])\\n        #print(image[cnt:cnt+1000,:,:], modulation[cnt:cnt+1000], snr[cnt:cnt+1000])\\n        cnt += 1000\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'RML2016.10a_dict.pkl'\n",
    "f = open(fname,'rb')\n",
    "input_data_dict = pickle.load(f, encoding='latin1')\n",
    "\n",
    "\"\"\"\n",
    "Data size is 1000*2*128\n",
    "Consider it as 1000 images of size 1*2*128. Where 1 is the color channel.\n",
    "We need the data in this format:\n",
    "\n",
    "image - mod - snr\n",
    "image - mod - snr\n",
    "image - mod - snr\n",
    "\n",
    "Create 3 arrays:\n",
    "image, mod, snr\n",
    "\"\"\"\n",
    "\n",
    "input_data_dict_keys = sorted(input_data_dict.keys())\n",
    "\n",
    "modulation_types    = [input_data_dict_keys[i*20][0] for i in range(0,11)]\n",
    "snr_types           = [input_data_dict_keys[i][1] for i in range(0,20)]\n",
    "\n",
    "print(modulation_types)\n",
    "print(snr_types)\n",
    "\n",
    "\n",
    "image = []\n",
    "modulation = []\n",
    "snr = []\n",
    "\n",
    "\n",
    "print(np.shape(image), np.shape(modulation), np.shape(snr))\n",
    "\n",
    "for m_cnt,m in enumerate(modulation_types,0):\n",
    "    for s in snr_types:\n",
    "        #print(m,str(s))\n",
    "        image.extend(input_data_dict[(m,s)])\n",
    "        modulation.extend([m_cnt for _ in range(0,1000)])\n",
    "        snr.extend([s for _ in range(0,1000)])\n",
    "        \n",
    "#print(np.shape(image), np.shape(modulation), np.shape(snr))\n",
    "image = np.array(image)\n",
    "modulation = np.array(modulation)\n",
    "snr = np.array(snr)\n",
    "\n",
    "\"\"\"\n",
    "image = np.zeros((220000,2,128), dtype='float32')\n",
    "modulation = np.zeros((220000), dtype='int32')\n",
    "snr = np.zeros((220000), dtype='int32')\n",
    "cnt = 0\n",
    "\n",
    "for m_cnt,m in enumerate(modulation_types,0):\n",
    "    for s in snr_types:\n",
    "        print(cnt, m_cnt,s)\n",
    "        #print(input_data_dict[(m,s)].shape)\n",
    "        image[cnt:cnt+1000,:,:] = np.array(input_data_dict[(m,s)])\n",
    "        modulation[cnt:cnt+1000] = np.array([m_cnt for _ in range(0,1000)])\n",
    "        snr[cnt:cnt+1000] = np.array([s for _ in range(0,1000)])\n",
    "        #print(image[cnt:cnt+1000,:,:], modulation[cnt:cnt+1000], snr[cnt:cnt+1000])\n",
    "        cnt += 1000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X,Y,Z, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Z = Z\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rX, rY, rZ = torch.unsqueeze(torch.from_numpy(self.X[idx]),dim=0).float(), torch.tensor(self.Y[idx]), torch.tensor(self.Z[idx])\n",
    "        if(self.transform):\n",
    "            rX, rY, rZ = self.transform(self.X[idx]),torch.tensor(self.Y[idx]),torch.tensor(self.Z[idx])\n",
    "            \n",
    "        return rX, rY, rZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = [image, modulation, snr]\n",
    "transformed_dataset = myDataset(image, modulation, snr,transforms.Compose([transforms.ToTensor(),transforms.Normalize((0,),(1,))]))\n",
    "#rX, rY, rZ = torch.unsqueeze(torch.from_numpy(image[0]),dim=0).float(), torch.tensor(modulation[0]), torch.tensor(snr[0])\n",
    "#print(type(rY))\n",
    "\n",
    "dataset_len = len(image)\n",
    "l = list(range(0, dataset_len))\n",
    "np.random.shuffle(l)\n",
    "split = 0.5\n",
    "train_indices, test_indices = l[:int(split*dataset_len)],l[int(split*dataset_len):]\n",
    "\n",
    "train_sampler=torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "test_sampler=torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "# train_sampler=torch.utils.data.SequentialSampler(train_indices)\n",
    "# test_sampler=torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(transformed_dataset, batch_size=128, shuffle=False, num_workers=2, sampler=train_sampler, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(transformed_dataset, batch_size=1, shuffle=False, num_workers=2, sampler=test_sampler, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "ModulationClassifier(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(256, 80, kernel_size=(2, 3), stride=(1, 1), padding=(0, 2))\n",
      "    (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10560, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=256, out_features=11, bias=True)\n",
      "  )\n",
      ")\n",
      "conv1.0.weight                          \ttorch.Size([256, 1, 1, 3])    \t       768\n",
      "conv1.0.bias                            \ttorch.Size([256])             \t       256\n",
      "conv1.1.weight                          \ttorch.Size([256])             \t       256\n",
      "conv1.1.bias                            \ttorch.Size([256])             \t       256\n",
      "conv2.0.weight                          \ttorch.Size([80, 256, 2, 3])   \t    122880\n",
      "conv2.0.bias                            \ttorch.Size([80])              \t        80\n",
      "conv2.1.weight                          \ttorch.Size([80])              \t        80\n",
      "conv2.1.bias                            \ttorch.Size([80])              \t        80\n",
      "classifier.0.weight                     \ttorch.Size([256, 10560])      \t   2703360\n",
      "classifier.0.bias                       \ttorch.Size([256])             \t       256\n",
      "classifier.2.weight                     \ttorch.Size([11, 256])         \t      2816\n",
      "classifier.2.bias                       \ttorch.Size([11])              \t        11\n"
     ]
    }
   ],
   "source": [
    "net = ModulationClassifier()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "net.to(device)\n",
    "\n",
    "print(net)\n",
    "for name, param in net.named_parameters():\n",
    "    #if param.requires_grad:\n",
    "    print('{:s}\\t{:s}\\t{:s}'.format(name.ljust(40), str(param.size()).ljust(30),str(param.nelement()).rjust(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8023028205300486\n",
      "0.5087926574917727\n",
      "0.4491056091563646\n",
      "0.4072604430276294\n",
      "0.3836330060348954\n",
      "0.3459082034091617\n",
      "0.31598821088325146\n",
      "0.28530036730821745\n",
      "0.26138566070517827\n",
      "0.2326782818450484\n",
      "0.20507257379764735\n",
      "0.18787415038014568\n",
      "0.16429393076619436\n",
      "0.14735244273446327\n",
      "0.13172882828255034\n",
      "0.11876257363446924\n",
      "0.11376052077773005\n",
      "0.10035927109420299\n",
      "0.09423685324226701\n",
      "0.0905521523727234\n",
      "0.08736600202703199\n",
      "0.08642896368753078\n",
      "0.0835414188719073\n",
      "0.0791843518614769\n",
      "0.07745748973169993\n",
      "0.07466897254073343\n",
      "0.07401477539435375\n",
      "0.07224483250012231\n",
      "0.07074032877247001\n",
      "0.06922459818942603\n",
      "0.07071248071138249\n",
      "0.06784668767521548\n",
      "0.06835336270200652\n",
      "0.06634778787576875\n",
      "0.0656068085497895\n",
      "0.06383736066000406\n",
      "0.06372993141412735\n",
      "0.06223439309139584\n",
      "0.0615888248869153\n",
      "0.07224563303035358\n",
      "0.08380863293139047\n",
      "0.1018014394699834\n",
      "0.0815504582295584\n",
      "0.06957547230602697\n",
      "0.0630239078211923\n",
      "0.05900522507727146\n",
      "0.05946746484138245\n",
      "0.05740791787068511\n",
      "0.054379840004582736\n",
      "0.055706948674348895\n",
      "0.05382014769454335\n",
      "0.0545512564913478\n",
      "0.052468418178343496\n",
      "0.05118872939154159\n",
      "0.05189175485351751\n",
      "0.050974085303240046\n",
      "0.050507436103599014\n",
      "0.048499388767536296\n",
      "0.048754233650343363\n",
      "0.04958639009747394\n",
      "0.04753722363952981\n",
      "0.04782174219225728\n",
      "0.045909520914388255\n",
      "0.0469460773606633\n",
      "0.04649731142576351\n",
      "0.04759713334226331\n",
      "0.049288670519410174\n",
      "0.058906937975349814\n",
      "0.05079735829819774\n",
      "0.047014514070957206\n",
      "0.04390948007186485\n",
      "0.04314420952699905\n",
      "0.041741895939894885\n",
      "0.04196342152738294\n",
      "0.04170310794440813\n",
      "0.039802520990718245\n",
      "0.040756676198784696\n",
      "0.03893477705328963\n",
      "0.03822492380994697\n",
      "0.03828977038867252\n",
      "0.04040960666918477\n",
      "0.03917504438134127\n",
      "0.03700517941006394\n",
      "0.03589952882855784\n",
      "0.03622640486546727\n",
      "0.03598646224411421\n",
      "0.035087573233731954\n",
      "0.03413431574265624\n",
      "0.03271503507397896\n",
      "0.03314131136203921\n",
      "0.03385994858000167\n",
      "0.033503592807019866\n",
      "0.03157387369334005\n",
      "0.0320438195756355\n",
      "0.033271695768763855\n",
      "0.035043704457754316\n",
      "0.03496398745581161\n",
      "0.03352984232871339\n",
      "0.03358827375395353\n",
      "0.030566611335894396\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "epoch_loss_array = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        x,y,z = data\n",
    "        x,y,z = x.to(device), y.to(device), z.to(device)\n",
    "        #x_mean = torch.mean(x, 1, keepdims=True)\n",
    "        #print(x.size(), y.size(), z.size(), x_mean.size())\n",
    "        #x = x - x_mean\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = net.forward(x)   # Run batch\n",
    "        #print(torch.argmax(y_pred, 1).size())\n",
    "        loss = criterion(y_pred, y.long())  # Wants indexes for labels, *not* one-hot encodings.\n",
    "        loss.backward()                               # Compute backprop\n",
    "        optimizer.step()                              # Move a step in the right direction\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #print( y, torch.argmax(y_pred,1))\n",
    "        #break\n",
    "        \n",
    "    print(running_loss/len(trainloader))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 78.981818 %\n"
     ]
    }
   ],
   "source": [
    "PATH = './temp_model_1.pth'\n",
    "torch.save(net.state_dict(), PATH) \n",
    "\n",
    "model1 = ModulationClassifier()\n",
    "model1.to(device)\n",
    "model1.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "snr_accuracy = dict()\n",
    "for i in range(-20,20,2):\n",
    "    k = str(i)\n",
    "    snr_accuracy[k] = [0,0]\n",
    "    \n",
    "model1.eval()\n",
    "for i,data in enumerate(testloader):\n",
    "    x,y,z = data\n",
    "    x,y,z = x.to(device), y.to(device), z.to(device)\n",
    "\n",
    "    y_pred = model1.forward(x)\n",
    "    correct += torch.sum((torch.argmax(y_pred,dim=1) == y)).item()\n",
    "    snr_value = z.item()\n",
    "\n",
    "    snr_accuracy[str(int(snr_value))][0] += torch.sum((torch.argmax(y_pred,dim=1) == y)).item()\n",
    "    snr_accuracy[str(int(snr_value))][1] += 1\n",
    "    \n",
    "    total += 1 #Increase by batch size\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR 0 Accuracy 0.704426\n",
      "SNR 2 Accuracy 0.770444\n",
      "SNR 4 Accuracy 0.785534\n",
      "SNR 6 Accuracy 0.801042\n",
      "SNR 8 Accuracy 0.800219\n",
      "SNR 10 Accuracy 0.805485\n",
      "SNR 12 Accuracy 0.806723\n",
      "SNR 14 Accuracy 0.806434\n",
      "SNR 16 Accuracy 0.805647\n",
      "SNR 18 Accuracy 0.812683\n"
     ]
    }
   ],
   "source": [
    "for key, values in snr_accuracy.items():\n",
    "    if(values[1]):\n",
    "        print('SNR {:s} Accuracy {:f}'.format(key, values[0]/values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
